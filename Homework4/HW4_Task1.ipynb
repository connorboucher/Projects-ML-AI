{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1326d75a-4656-440a-b4f2-65b587829b04",
   "metadata": {},
   "source": [
    "I picked the yelp poplarity reviews dataset from the Tensorflow datasets catalog located at https://www.tensorflow.org/datasets/catalog/yelp_polarity_reviews. I wanted to be able to perform text classification on this dataset, as sequence models are useful for machine learning situations that take in sequential data, which this dataset uses in the form of text streams.  I chose to use the Bidirectional RNN framework from Tensorflow as that is where I got my dataset and thought the two were the most likely to be compatable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9043a508-4603-4763-b370-9060b390e1b5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-10-13 22:22:41.654593: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
      "2021-10-13 22:22:41.654645: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import tensorflow_datasets as tfds\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cdac7421-7c23-4f72-ae65-90bf940d4a74",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-10-13 22:22:47.576335: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory\n",
      "2021-10-13 22:22:47.576394: W tensorflow/stream_executor/cuda/cuda_driver.cc:269] failed call to cuInit: UNKNOWN ERROR (303)\n",
      "2021-10-13 22:22:47.576437: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (DESKTOP-J2H6DT8): /proc/driver/nvidia/version does not exist\n",
      "2021-10-13 22:22:47.576947: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(TensorSpec(shape=(), dtype=tf.string, name=None),\n",
       " TensorSpec(shape=(), dtype=tf.int64, name=None))"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset, info = tfds.load('yelp_polarity_reviews', with_info=True, as_supervised=True)\n",
    "train_dataset = dataset['train']\n",
    "test_dataset = dataset['test']\n",
    "\n",
    "train_dataset.element_spec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "23d332f6-50ac-4730-8a59-99623c10d956",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "text:  b\"The Groovy P. and I ventured to his old stomping grounds for lunch today.  The '5 and Diner' on 16th St and Colter left me with little to ask for.  Before coming here I had a preconceived notion that 5 & Diners were dirty and nasty. Not the case at all.\\\\n\\\\nWe walk in and let the waitress know we want to sit outside (since it's so nice and they had misters).  We get two different servers bringing us stuff (talk about service) and I ask the one waitress for recommendations.  I didn't listen to her, of course, and ordered the Southwestern Burger w/ coleslaw and started with a nice stack of rings.\\\\n\\\\nThe Onion Rings were perfectly cooked.  They looked like they were prepackaged, but they were very crispy and I could actually bite through the onion without pulling the entire thing out (don't you hate that?!!!)\\\\n\\\\nThe Southwestern Burger was order Medium Rare and was cooked accordingly.  Soft, juicy, and pink with a nice crispy browned outer layer that can only be achieved on a well used grill.  The creaminess of the chipotle mayo paired beautifully with the green chiles.  Unfortunately, because I ate too many onion rings, I couldn't finish my burger.  What a shame!\\\\n\\\\nThe Coleslaw was just how I like it.  It's hard to find a really good coleslaw.  I prefer mine to be slightly sweet, not sour.  Too much vinegar in slaw ruins it in my opinion.  This slaw had the perfect marriage of mayo, vinegar, and sugar. Not to mention carrots...\\\\n\\\\nMy experience here was great!  The servers were top notch and kept my water full the entire time and actually chatted with us for a few minutes.\\\\n\\\\nThere is an artist guy named Ross who has been there every day for 5393 days straight. No, not an employee.  He goes there and does his art! He hasn't missed a SINGLE day!!! That's like... 15 years! So if you wanna seem to be 'in the know' ask where Ross is... They'll be able to tell you.\\\\n\\\\nTime for a nap!\"\n",
      "label:  1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-10-13 22:22:48.552350: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:185] None of the MLIR Optimization Passes are enabled (registered 2)\n"
     ]
    }
   ],
   "source": [
    "for example, label in train_dataset.take(1):\n",
    "  print('text: ', example.numpy())\n",
    "  print('label: ', label.numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "29747d77-4b68-40d4-8f47-dbc3e2097a4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "BUFFER_SIZE = 10000\n",
    "BATCH_SIZE = 64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "bf7aa767-17d6-4b3b-bfee-9d19a98a7fdf",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = train_dataset.shuffle(BUFFER_SIZE).batch(BATCH_SIZE).prefetch(tf.data.AUTOTUNE)\n",
    "test_dataset = test_dataset.batch(BATCH_SIZE).prefetch(tf.data.AUTOTUNE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "da8e523a-d1d8-422e-8b15-86a74dea91a3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "texts:  [b'RE: Food poisoning\\\\n\\\\nApril 26 @ 8pm, my girlfriends and I went for a quick dinner before we catch our Cirque show @ 9:30pm. I ordered the gnocchi lobster ragu. The first bite was already off as the seafood smell and taste was very strong (like bad unfresh seafood strong), but I brushed it off as the robust /deep flavour of the ragu. I offered my girlfriend (bride-to-be for this trip) took one bite. We both were feeling sick sitting through the show and went straight back to our hotel room. Within seconds to the porcelain throne,  I vomited violently for about 5 minutes and my gf was also for the remainder of the night. She was left in bed for over 24 hours in our hotel room. After I reported to the Front Desk Manager, he apologized but no follow up phone call was made to us.\\\\n\\\\nExtremely disappointed in the customer service and bad seafood we were served.'\n",
      " b'This is really only a half-revue, because I never ended up eating here due to the following:\\\\n\\\\nI got their menu in the mail and it looked good, so I went to see the place. The building exterior should have been a big red warning, it was grungy. Walking up to the front door you notice the absolutely filthy windows that are so dirty and smeared you cant really see through them. I went in and noticed all of the pealing wall paper and filthy floor corners and table feet, then there was the terrible smell permeating the place of rancid fishy frying grease, it almost made me sick--I had to leave.\\\\n\\\\n This place is dirty!  I have worked in food long enough to know that if the front of the house is this bad then the kitchen is going to be ten times worse. These people clearly have scraped this place together to try and make a buck and nothing else.\\\\n\\\\nI find it mind blowing that this \\\\\"\"restaurant\\\\\"\" can even get a passing score from the Dane Co. Health Dept.'\n",
      " b\"In Short...Decent Atmosphere, Average overall food Quality...WAAYYY Too Expensive.\\\\n\\\\nFor a place famous for it's steaks and ribs I was sorely disappointed. I was with a group of about 7 people. The Big Hamburger that was ordered medium by one person in my party came well done and dry as the desert. The initial helping of all you can eat beef ribs was pretty good...if a little too saucy...with the meat falling off the bone. but the additional helpings were AWFUL!!! TERRIBLY under cooked and had to order 2 additional helpings just to get 3 bites of edible meat...the second helping didn't even appear to have been cooked and I had to fight to get 3 bites off of EIGHT Ribs....Just Awful.\\\\n\\\\nThe Outback, Texas Roadhouse and Saltgrass Steakhouse are less expensive and provide much better fare. \\\\n\\\\nThe atmosphere is country western with a band that plays occasionally and virtually all the staff we dealt with were friendly and accommodating. If only the food was better I might have been abe to give this place 3 maybe even 4 stars, but it is a restaurant after all...so good food should be the focus\"]\n",
      "\n",
      "labels:  [0 0 0]\n"
     ]
    }
   ],
   "source": [
    "for example, label in train_dataset.take(1):\n",
    "  print('texts: ', example.numpy()[:3])\n",
    "  print()\n",
    "  print('labels: ', label.numpy()[:3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c1a32764-8dcc-4fc8-9a7f-c86874d72ac3",
   "metadata": {},
   "outputs": [],
   "source": [
    "VOCAB_SIZE = 1000\n",
    "encoder = tf.keras.layers.experimental.preprocessing.TextVectorization(\n",
    "    max_tokens=VOCAB_SIZE)\n",
    "encoder.adapt(train_dataset.map(lambda text, label: text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "256ba3e2-c1a1-47a9-b8f4-828706e4218f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['', '[UNK]', 'the', 'and', 'i', 'to', 'a', 'was', 'of', 'it',\n",
       "       'for', 'in', 'is', 'that', 'my', 'we', 'this', 'with', 'but',\n",
       "       'they'], dtype='<U13')"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocab = np.array(encoder.get_vocabulary())\n",
    "vocab[:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "551e3b77-ca22-46d7-8495-9ec64dc99665",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  1,  30,   1, ...,   0,   0,   0],\n",
       "       [ 16,  12,  62, ...,   0,   0,   0],\n",
       "       [ 11,   1, 355, ...,   0,   0,   0]])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoded_example = encoder(example)[:3].numpy()\n",
    "encoded_example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ac1b3b9a-e3f2-4935-8410-a2f4edb2b0cc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original:  b'RE: Food poisoning\\\\n\\\\nApril 26 @ 8pm, my girlfriends and I went for a quick dinner before we catch our Cirque show @ 9:30pm. I ordered the gnocchi lobster ragu. The first bite was already off as the seafood smell and taste was very strong (like bad unfresh seafood strong), but I brushed it off as the robust /deep flavour of the ragu. I offered my girlfriend (bride-to-be for this trip) took one bite. We both were feeling sick sitting through the show and went straight back to our hotel room. Within seconds to the porcelain throne,  I vomited violently for about 5 minutes and my gf was also for the remainder of the night. She was left in bed for over 24 hours in our hotel room. After I reported to the Front Desk Manager, he apologized but no follow up phone call was made to us.\\\\n\\\\nExtremely disappointed in the customer service and bad seafood we were served.'\n",
      "\n",
      "Round-trip:  [UNK] food [UNK] [UNK] [UNK] my [UNK] and i went for a quick dinner before we [UNK] our [UNK] show [UNK] i ordered the [UNK] lobster [UNK] the first bite was already off as the seafood smell and taste was very [UNK] like bad [UNK] seafood [UNK] but i [UNK] it off as the [UNK] [UNK] [UNK] of the [UNK] i offered my [UNK] [UNK] for this trip took one bite we both were feeling [UNK] sitting through the show and went [UNK] back to our hotel room within [UNK] to the [UNK] [UNK] i [UNK] [UNK] for about 5 minutes and my [UNK] was also for the [UNK] of the night she was left in bed for over [UNK] hours in our hotel room after i [UNK] to the front desk manager he [UNK] but no [UNK] up phone call was made to [UNK] disappointed in the customer service and bad seafood we were served                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                   \n",
      "\n",
      "Original:  b'This is really only a half-revue, because I never ended up eating here due to the following:\\\\n\\\\nI got their menu in the mail and it looked good, so I went to see the place. The building exterior should have been a big red warning, it was grungy. Walking up to the front door you notice the absolutely filthy windows that are so dirty and smeared you cant really see through them. I went in and noticed all of the pealing wall paper and filthy floor corners and table feet, then there was the terrible smell permeating the place of rancid fishy frying grease, it almost made me sick--I had to leave.\\\\n\\\\n This place is dirty!  I have worked in food long enough to know that if the front of the house is this bad then the kitchen is going to be ten times worse. These people clearly have scraped this place together to try and make a buck and nothing else.\\\\n\\\\nI find it mind blowing that this \\\\\"\"restaurant\\\\\"\" can even get a passing score from the Dane Co. Health Dept.'\n",
      "\n",
      "Round-trip:  this is really only a [UNK] because i never ended up eating here due to the [UNK] got their menu in the [UNK] and it looked good so i went to see the place the [UNK] [UNK] should have been a big red [UNK] it was [UNK] walking up to the front door you [UNK] the absolutely [UNK] [UNK] that are so dirty and [UNK] you cant really see through them i went in and noticed all of the [UNK] wall [UNK] and [UNK] floor [UNK] and table [UNK] then there was the terrible smell [UNK] the place of [UNK] [UNK] [UNK] [UNK] it almost made me [UNK] had to [UNK] this place is dirty i have worked in food long enough to know that if the front of the house is this bad then the kitchen is going to be [UNK] times worse these people clearly have [UNK] this place together to try and make a [UNK] and nothing [UNK] find it mind [UNK] that this restaurant can even get a [UNK] [UNK] from the [UNK] [UNK] [UNK] [UNK]                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                           \n",
      "\n",
      "Original:  b\"In Short...Decent Atmosphere, Average overall food Quality...WAAYYY Too Expensive.\\\\n\\\\nFor a place famous for it's steaks and ribs I was sorely disappointed. I was with a group of about 7 people. The Big Hamburger that was ordered medium by one person in my party came well done and dry as the desert. The initial helping of all you can eat beef ribs was pretty good...if a little too saucy...with the meat falling off the bone. but the additional helpings were AWFUL!!! TERRIBLY under cooked and had to order 2 additional helpings just to get 3 bites of edible meat...the second helping didn't even appear to have been cooked and I had to fight to get 3 bites off of EIGHT Ribs....Just Awful.\\\\n\\\\nThe Outback, Texas Roadhouse and Saltgrass Steakhouse are less expensive and provide much better fare. \\\\n\\\\nThe atmosphere is country western with a band that plays occasionally and virtually all the staff we dealt with were friendly and accommodating. If only the food was better I might have been abe to give this place 3 maybe even 4 stars, but it is a restaurant after all...so good food should be the focus\"\n",
      "\n",
      "Round-trip:  in [UNK] atmosphere average overall food [UNK] too [UNK] a place [UNK] for its [UNK] and ribs i was [UNK] disappointed i was with a group of about 7 people the big [UNK] that was ordered medium by one person in my party came well done and dry as the [UNK] the [UNK] [UNK] of all you can eat beef ribs was pretty [UNK] a little too [UNK] the meat [UNK] off the [UNK] but the [UNK] [UNK] were awful [UNK] under cooked and had to order 2 [UNK] [UNK] just to get 3 [UNK] of [UNK] [UNK] second [UNK] didnt even [UNK] to have been cooked and i had to [UNK] to get 3 [UNK] off of [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] and [UNK] [UNK] are less expensive and [UNK] much better [UNK] nnthe atmosphere is [UNK] [UNK] with a [UNK] that [UNK] [UNK] and [UNK] all the staff we [UNK] with were friendly and [UNK] if only the food was better i might have been [UNK] to give this place 3 maybe even 4 stars but it is a restaurant after [UNK] good food should be the [UNK]                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                \n",
      "\n"
     ]
    }
   ],
   "source": [
    "for n in range(3):\n",
    "  print(\"Original: \", example[n].numpy())\n",
    "  print(\"\\nRound-trip: \", \" \".join(vocab[encoded_example[n]]))\n",
    "  print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "df9ea676-30a7-4b3a-ab13-69d997c9544a",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tf.keras.Sequential([\n",
    "    encoder,\n",
    "    tf.keras.layers.Embedding(\n",
    "        input_dim=len(encoder.get_vocabulary()),\n",
    "        output_dim=64,\n",
    "        mask_zero=True),\n",
    "    tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(64)),\n",
    "    tf.keras.layers.Dense(64, activation='relu'),\n",
    "    tf.keras.layers.Dense(1)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "738289e0-afe3-4850-b5d6-43d0980344b6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[4.067574]\n"
     ]
    }
   ],
   "source": [
    "sample_text = ('This place has an awesome vegetarian/vegan menu option!!'\n",
    "               'Everything was very tasty.')\n",
    "predictions = model.predict(np.array([sample_text]))\n",
    "print(predictions[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "93f9b14d-58ae-4ce8-ace8-1708aa9e8e52",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss=tf.keras.losses.BinaryCrossentropy(from_logits=True),\n",
    "              optimizer=tf.keras.optimizers.Adam(1e-4),\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "7f0a304a-edf9-4918-b006-ff92706ba465",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8750/8750 [==============================] - 4908s 561ms/step - loss: 0.2261 - accuracy: 0.9025 - val_loss: 0.1946 - val_accuracy: 0.9167\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(train_dataset, epochs=1,\n",
    "                    validation_data=test_dataset,\n",
    "                    validation_steps=30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "690905fb-f05b-4e98-b044-f1c4beca6065",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "594/594 [==============================] - 69s 116ms/step - loss: 0.2120 - accuracy: 0.9109\n",
      "Test Loss: 0.21200621128082275\n",
      "Test Accuracy: 0.9108684062957764\n"
     ]
    }
   ],
   "source": [
    "test_loss, test_acc = model.evaluate(test_dataset)\n",
    "\n",
    "print('Test Loss:', test_loss)\n",
    "print('Test Accuracy:', test_acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff083d8f-a118-4f2a-b05b-a59cfdd50531",
   "metadata": {},
   "source": [
    "Task 1:\n",
    "The structure of this RNN is multiple layers starting with an encoder to convert the text stream and an embedding layer to convert the data a second time into trainable vectors.  The relu activation function is used while training in this structure.  Following this is a bidirectional wrapper which is used for running the inputs in two ways which allows the network to preserve information when training.  Lastly, this RNN structure uses two dense layers for converting the trained output vectors into a single output.  The metric I am using to measure performance is the built in accuracy metric in the compile function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "179be988-96b9-40b7-b034-fc3aa542fb63",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tf.keras.Sequential([\n",
    "    encoder,\n",
    "    tf.keras.layers.Embedding(len(encoder.get_vocabulary()), 64, mask_zero=True),\n",
    "    tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(64,  return_sequences=True)),\n",
    "    tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(32)),\n",
    "    tf.keras.layers.Dense(64, activation='relu'),\n",
    "    tf.keras.layers.Dropout(0.5),\n",
    "    tf.keras.layers.Dense(1)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "8c52bbb0-0763-45f7-9dde-01b4fceeea33",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss=tf.keras.losses.BinaryCrossentropy(from_logits=True),\n",
    "              optimizer=tf.keras.optimizers.Adam(1e-4),\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "803ab833-f7b6-4308-b829-0e94cf14f0ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8750/8750 [==============================] - 7155s 817ms/step - loss: 0.2560 - accuracy: 0.8873 - val_loss: 0.1951 - val_accuracy: 0.9146\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(train_dataset, epochs=1,\n",
    "                    validation_data=test_dataset,\n",
    "                    validation_steps=30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "ea9513e9-6b59-4923-b8c4-41b5b68bd9a2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "594/594 [==============================] - 116s 196ms/step - loss: 0.2123 - accuracy: 0.9088\n",
      "Test Loss: 0.21233096718788147\n",
      "Test Accuracy: 0.9087894558906555\n"
     ]
    }
   ],
   "source": [
    "test_loss, test_acc = model.evaluate(test_dataset)\n",
    "\n",
    "print('Test Loss:', test_loss)\n",
    "print('Test Accuracy:', test_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "80f54caf-68b5-4bd8-9419-65b5cf5666b0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[4.067574]]\n"
     ]
    }
   ],
   "source": [
    "sample_text = ('This place has an awesome vegetarian/vegan menu option!!'\n",
    "               'Everything was very tasty.')\n",
    "predictions = model.predict(np.array([sample_text]))\n",
    "print(predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d475e442-d7f4-4941-8aaf-10cc6a2dac34",
   "metadata": {},
   "source": [
    "Task 2:\n",
    "I did not notice any major differences in my results between the two trainings.  One major issue I came into was that fact that my data was incredibly slow to train, so I was only able to get one epoch to finish.  Each training took upwards of 3 hours to complete one epoch only, so this could have a large effect on why my results were so similar."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
